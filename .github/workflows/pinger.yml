# .github/workflows/pinger.yml
name: Ping D1 Links

on:
  schedule:
    # Runs at every 10:50 hours, every day.
    - cron: '50 */10 * * *'
  workflow_dispatch:
    # Allows you to run this workflow manually from the Actions tab

jobs:
  ping-links:
    runs-on: ubuntu-latest
    steps:
      - name:  checkout code
        uses: actions/checkout@v4

      - name: ðŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: ðŸš€ Fetch Links via Cloudflare API (with Debugging)
        run: |
          echo "--- Fetching links directly from D1 HTTP API ---"
          
          # 1. Run curl and save the RAW response to 'd1_response.json'
          #    This stops jq from hiding any API errors.
          curl -s -X POST \
            "https://api.cloudflare.com/client/v4/accounts/${{ secrets.CLOUDFLARE_ACCOUNT_ID }}/d1/database/${{ secrets.D1_DATABASE_ID }}/query" \
            --header "Authorization: Bearer ${{ secrets.CLOUDFLARE_API_TOKEN }}" \
            --header "Content-Type: application/json" \
            --data '{ "sql": "SELECT download_link FROM links;", "params": [] }' > d1_response.json
          
          echo "--- DEBUG: RAW RESPONSE from Cloudflare API ---"
          # This is the most important step: print what Cloudflare actually sent.
          cat d1_response.json
          echo "------------------------------------------------"
          
          # 2. Try to process the response with jq
          echo "--- Processing response with jq... ---"
          jq '.result[0].results' d1_response.json > links.json
          
          echo "âœ… Raw response processed and saved to links.json"

          echo "--- DEBUG: FINAL CONTENT of links.json (what script will read) ---"
          # This shows what the Node.js script will get.
          cat links.json
          echo "------------------------------------------------------------------"

      - name: Pinging Links
        run: node ping-script.js
